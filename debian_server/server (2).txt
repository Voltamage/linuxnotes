When using hostnames, the first server needs to be probed from one other server to set its hostname.

sudo glusterfs --version
$SERVER1: sudo gluster peer probe $SERVER2
$SERVER2: sudo gluster peer probe $SERVER1
$SERVER1: sudo gluster peer status
$SERVER2: sudo gluster peer status
sudo gluster peer status
sudo gluster pool list

sudo gluster volume create $VOLUMENAME replica 2 $SERVERNAME1:/mnt/gluster/brick $SERVERNAME2:/mnt/gluster/brick
sudo gluster volume info
sudo gluster volume start $VOLUMENAME
sudo gluster volume info

sudo gluster volume bitrot <VOLNAME> enable
sudo gluster volume bitrot <VOLNAME> scrub-throttle lazy
sudo gluster volume bitrot <VOLNAME> scrub-frequency weekly
sudo gluster volume set $VOLUMENAME features.trash on
sudo gluster volume set $VOLUMENAME features.trash-internal-op on

Configure Firewall

For the Gluster to communicate within a cluster either the firewalls have to be turned off or enable communication for each server.

# iptables -I INPUT -p all -s `<ip-address>` -j ACCEPT


For this step, we will use one of the servers to mount the volume. Typically, you would do this from an external machine, known as a "client". Since using this method would require additional packages to be installed on the client machine, we will use one of the servers as a simple place to test first , as if it were that "client".

# mount -t glusterfs server1:/gv0 /mnt
# for i in `seq -w 1 100`; do cp -rp /var/log/messages /mnt/copy-test-$i; done

First, check the client mount point:

# ls -lA /mnt/copy* | wc -l

You should see 100 files returned. Next, check the GlusterFS brick mount points on each server:

is debian glusterfs too old

# ls -lA /data/brick1/gv0/copy*

You should see 100 files on each server using the method we listed here. Without replication, in a distribute only volume (not detailed here), you should see about 33 files on each one.
For this step, we will use one of the servers to mount the volume. Typically, you would do this from an external machine, known as a "client". Since using this method would require additional packages to be installed on the client machine, we will use one of the servers as a simple place to test first , as if it were that "client".

# mount -t glusterfs server1:/gv0 /mnt
# for i in `seq -w 1 100`; do cp -rp /var/log/messages /mnt/copy-test-$i; done

First, check the client mount point:

# ls -lA /mnt/copy* | wc -l

You should see 100 files returned. Next, check the GlusterFS brick mount points on each server:

# ls -lA /data/brick1/gv0/copy*

You should see 100 files on each server using the method we listed here. Without replication, in a distribute only volume (not detailed here), you should see about 33 files on each one.

For this test, if you do not have DNS set up, you can get away with using /etc/hosts entries for the two nodes. However, when you move from this basic setup to using Gluster in production, correct DNS entries (forward and reverse) and NTP are essential.

Firewalls are great, except when they arenâ€™t. For storage servers, being able to operate in a trusted environment without firewalls can mean huge gains in performance, and is recommended. In case you absolutely need to set up a firewall, have a look at Setting up clients for information on the ports used.

sudo gluster volume rebalance <volname> fix-layout start
sudo gluster volume rebalance <volume> start
sudo gluster volume rebalance <VOLNAME> start force
sudo gluster volume rebalance <VOLNAME> status
sudo gluster volume rebalance <VOLNAME> stop

sudo gluster volume remove-brick <VOLNAME> <BRICKNAME> start
sudo gluster volume remove-brick <VOLNAME> <BRICKNAME> status
sudo gluster volume remove-brick <VOLNAME> <BRICKNAME> commit
sudo gluster volume info
CLIENT
yay -S glusterfs OR sudo apt-get install glusterfs-client
sudo modprobe fuse
dmesg | grep -i fuse
sudo mkdir $MOUNTPOINT
	add to /etc/fstab:
$SERVERNAME1:/$VOLUMENAME $MOUNTPOINT glusterfs defaults,_netdev 0 0
sudo mount -a
mount | grep glusterfs
df -h

ADDING BRICKS
sudo gluster peer probe $NEWSERVERNAME
sudo gluster volume add-brick $VOLUMENAME $NEWSERVERNAME1:/mnt/gluster/brick $NEWSERVERNAME2:/mnt/gluster/brick
sudo gluster volume info $VOLUMENAME
sudo gluster volume status

REBALANCING
sudo gluster volume rebalance $VOLUMENAME start force

HEALING
sudo gluster volume heal $VOLUMENAME info
sudo gluster volume heal $VOLUMENAME
sudo gluster volume heal $VOLUMENAME info healed
sudo gluster volume heal $VOLUMENAME info failed
sudo gluster volume heal $VOLUMENAME info split-brained

A rebalance operation will attempt to balance the diskusage across nodes, therefore it will skip files where the move will result in a less balanced volume. This leads to link files that are still left behind in the system and hence may cause performance issues. The behaviour can be overridden with the force argument.

sudo gluster volume bitrot $VOLUMENAME scrub-throttle normal
sudo gluster volume bitrot $VOLUMENAME scrub-frequency biweekly

log sizes?

sudo gluster volume create oceanus replica 2 transport tcp oceanus01:/data/glusterfs/oceanus/brick01/brick oceanus02:/data/glusterfs/oceanus/brick01/brick

       -a, --archive
              This  is equivalent to -rlptgoD. It is a quick way of saying you want recursion and want to preserve
              almost everything (with -H being a notable omission).  The only exception to the  above  equivalence
              is when --files-from is specified, in which case -r is not implied.

              Note  that  -a does not preserve hardlinks, because finding multiply-linked files is expensive.  You
              must separately specify -H.
			  
			  tmux new -s transfer
			  
			  tmux
			  ssh $IP
			  tmux ls
			  tmux attach -t transfer
msrsync --processes 16 --buckets ~/buckets --show --progress --stats --dry-run --rsync "--archive --xattrs" ~/old ~/server/old

find ~/what/u/want/ -type f -print0 | xargs -0 mv -t ~/where/u/want
perl-rename 's/oldshit/newshit/' **
perl -e 'for(<*>){((stat)[9]<(unlink))}'

ls -R | wc --lines

192.168.2.99	zeus
192.168.2.100	apollo
192.168.2.101	oceanus01
192.168.2.102	oceanus02
192.168.2.103	oceanus03
192.168.2.104	oceanus04

tmux new -s $SESSIONNAME
tmux attach-session $SESSIONNAME

Running remove-brick with cluster.force-migration enabled can result in data corruption. It is safer to disable this option so that files that receive writes during migration are not migrated.
Files that are not migrated can then be manually copied after the remove-brick commit operation.
sudo gluster volume set oceanus cluster.force-migration off
sudo gluster volume set oceanus cluster.force-migration on
