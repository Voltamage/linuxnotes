sudo glusterfs --version
sudo gluster peer probe $SERVERNAME
sudo gluster peer status
sudo gluster pool list
sudo gluster volume create $VOLUMENAME replica 2 transport tcp $SERVERNAME1:/mnt/$VOLUMENAME/brick $SERVERNAME2:/mnt/$VOLUMENAME/brick
sudo gluster volume info
sudo gluster volume start $VOLUMENAME

sudo gluster volume bitrot $VOLUMENAME enable
sudo gluster volume bitrot $VOLUMENAME scrub-throttle lazy
sudo gluster volume bitrot $VOLUMENAME scrub-frequency daily
sudo gluster volume set $VOLUMENAME features.trash on
sudo gluster volume set $VOLUMENAME features.trash-internal-op on

CLIENT
sudo modprobe fuse
mkdir ~/server
(In fstab)
$SERVERNAME1:/$VOLUMENAME /home/$USER/server glusterfs defaults,_netdev 0 0
(REBOOT)
df -h

ADDING BRICKS
sudo gluster peer probe $NEWSERVERNAME
sudo gluster volume add-brick $VOLUMENAME $NEWSERVERNAME1:/data/glusterfs/$VOLUMENAME/brick01/brick $NEWSERVERNAME2:/data/glusterfs/$VOLUMENAME/brick01/brick
sudo gluster volume info
sudo gluster volume status

REBALANCING
sudo gluster volume rebalance $VOLUMENAME start force

HEALING
sudo gluster volume heal $VOLUMENAME info
sudo gluster volume heal $VOLUMENAME
sudo gluster volume heal $VOLUMENAME info healed
sudo gluster volume heal $VOLUMENAME info failed
sudo gluster volume heal $VOLUMENAME info split-brained

A rebalance operation will attempt to balance the diskusage across nodes, therefore it will skip files where the move will result in a less balanced volume. This leads to link files that are still left behind in the system and hence may cause performance issues. The behaviour can be overridden with the force argument.

sudo gluster volume bitrot $VOLUMENAME scrub-throttle normal
sudo gluster volume bitrot $VOLUMENAME scrub-frequency biweekly

log sizes?

sudo gluster volume create oceanus replica 2 transport tcp oceanus01:/data/glusterfs/oceanus/brick01/brick oceanus02:/data/glusterfs/oceanus/brick01/brick

       -a, --archive
              This  is equivalent to -rlptgoD. It is a quick way of saying you want recursion and want to preserve
              almost everything (with -H being a notable omission).  The only exception to the  above  equivalence
              is when --files-from is specified, in which case -r is not implied.

              Note  that  -a does not preserve hardlinks, because finding multiply-linked files is expensive.  You
              must separately specify -H.
			  
			  tmux new -s transfer
			  
			  tmux
			  ssh $IP
			  tmux ls
			  tmux attach -t transfer
msrsync --processes 16 --buckets ~/buckets --show --progress --stats --dry-run --rsync "--archive --xattrs" ~/old ~/server/old

find ~/what/u/want/ -type f -print0 | xargs -0 mv -t ~/where/u/want
perl-rename 's/oldshit/newshit/' **
perl -e 'for(<*>){((stat)[9]<(unlink))}'

ls -R | wc --lines

192.168.2.99	zeus
192.168.2.100	apollo
192.168.2.101	oceanus01
192.168.2.102	oceanus02
192.168.2.103	oceanus03
192.168.2.104	oceanus04

tmux new -s $SESSIONNAME
tmux attach-session $SESSIONNAME

Running remove-brick with cluster.force-migration enabled can result in data corruption. It is safer to disable this option so that files that receive writes during migration are not migrated.
Files that are not migrated can then be manually copied after the remove-brick commit operation.
sudo gluster volume set oceanus cluster.force-migration off
sudo gluster volume set oceanus cluster.force-migration on
